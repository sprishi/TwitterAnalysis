---
title: "TwitterAnalysis"
author: "Subhankar Pattnaik"
date: "May 1, 2017"
output: html_document
---

**Name:** *Subhankar Pattnaik*
**ID:** *71710059*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## This project analyzes the tweets thereby giving out top twitter handles involved in conversation, top hastags used, top words used along top bigrams (two words) occured.  

**Load the required libraries**
```{r}
try(require(tm) || install.packages("tm"))
try(require(stringr) || install.packages("stringr", dependencies = TRUE))
try(require(dplyr) || install.packages("dplyr"))
try(require(tidytext) || install.packages("tidytext"))
try(require(tidyr) || install.packages("tidyr"))
try(require(gsubfn) || install.packages("gsubfn", dependencies = TRUE))
try(require(wordcloud) || install.packages("wordcloud"))
library(tm)
library(stringr)
library(dplyr)
library(tidytext)
library(tidyr)
library(gsubfn)
library(wordcloud)
```

**The below function is used basically to clean the tweets along with giving out some insights like top words, hastags, handles etc**
```{r}
twitter.analysis <- function(temp.text) {
  
  # Length of Tweets
  print("Length of tweets - ")
  print(length(temp.text$text))
  cat('\n')
  x <- temp.text$text
  twitter.df <- NULL
  
  # Extract all the twitter handles present in the list of tweets  
  twitter.hashtag <- unlist(strapplyc(x,"\\#\\w+"))   # extract twitter handles
  
  # Extract all the twitter hashtags present in the list of tweets
  twitter.handle <- unlist(strapplyc(x,"\\@\\w+"))  # extract twitter hashtags
  
  # function to clean tweets
  clean_Twitter_Corpus <- function(x) {
    
    x  =  gsub("\\\\x[89a-f][0-9a-f]", "", x) # remove latin encoded characters
    x  =  gsub("(ftp|http|https):\\/\\/(\\w+:{0,1}\\w*@)?(\\S+)(:[0-9]+)?(\\/|\\/([\\w#!:.?+=&%@!\\-\\/]))?", " ", x) # remove http urls
    x  =  gsub("^(b\'RT|b\'|b\"RT|b\"|via)", "", x) # remove b character
    x  =  gsub('#\\w+|@\\w+',' ',x)           # remove hastags and @ 
    x  =  gsub("<.*?>", " ", x)               # regex for removing HTML tags
    x  =  iconv(x, "latin1", "ASCII", sub="") # Keep only ASCII characters
    x  =  gsub("[^[:alnum:]]", " ", x)        # keep only alpha numeric
    x  =  tolower(x)                          # convert to lower case characters
    x  =  removeNumbers(x)                    # removing numbers
    x  =  stripWhitespace(x)                  # removing white space
    x  =  gsub("^\\s+|\\s+$", "", x)          # remove leading and trailing white space
  
    return(x)
  }    
  
  # clean the twitter texts. call the clean_Twitter_Corpus function
  tweets <- clean_Twitter_Corpus(x)
  
  # top 5 hashtags
  tbl.tag <- table(twitter.hashtag)
  hashtags <- tbl.tag[order(tbl.tag, decreasing = T)] %>% head(5)
  print(hashtags)
  twitter.df$top_hashtags <- row.names(hashtags)
  cat('\n')
  
  # top 5 handles
  tbl.hdl <- table(twitter.handle)
  handles <- tbl.hdl[order(tbl.hdl, decreasing = T)] %>% head(5)
  print(handles)
  twitter.df$top_handles <- row.names(handles)
  cat('\n')
  
  # store the tweets into dataframe
  textdf = data_frame(text = tweets) 
  
  # top 5 unigrams
  unigrams <- textdf %>% unnest_tokens(word, text) %>% count(word, sort = TRUE) %>% rename(count = n) %>% anti_join(stop_words) %>% head(5)
  print(unigrams)
  twitter.df$top_words <- unigrams$word
  cat('\n')
  
  # top 5 bigrams
  bigrams <- textdf %>% unnest_tokens(bigram, text, token = "ngrams", n = 2) %>% separate(bigram, c("word1", "word2"), sep = " ") %>% 
    filter(!word1 %in% stop_words$word) %>% filter(!word2 %in% stop_words$word) %>%
    unite(bigram, word1, word2, sep = " ") %>%
    count(bigram, sort = TRUE) %>% head(5)
  print(bigrams)
  twitter.df$top_bigrams <- bigrams$bigram
  cat('\n')
  
  # word cloud
  textdf %>%
    unnest_tokens(word, text) %>%
    anti_join(stop_words) %>%
    count(word) %>%
    with(wordcloud(word, n, max.words = 100))
  
  # data frame with columns 'top_words', 'top_bigrams', 'top_hashtags' and 'top_handles'
  twitter.df <- as.data.frame(twitter.df, stringsAsFactors=FALSE)
  twitter.df
}
```

##Read input files containing list of tweets and then pass to the predefined twitter.analysis function to get few insights for the concerned topic

**Read @IBMResearch tweets**
```{r, message=FALSE, warning=FALSE}
research.tweets <- read.csv(file.choose(), header=TRUE, sep=",", stringsAsFactors=FALSE, encoding = "Latin-1")
twitter.analysis(research.tweets)
```
```{r}

```
**Read @IBMWatson tweets**
```{r, message=FALSE, warning=FALSE}
watson.tweets <- read.csv(file.choose(), header=TRUE, sep=",", stringsAsFactors=FALSE, encoding = "Latin-1")
twitter.analysis(watson.tweets)
```

**From the above word clouds for the two sets of tweets i.e. of IBMResearch and IBMWatson we observe that words ibm, amp, cognitive, watson occured a lot. Popular handles are IBM, IBMWatson, IBMResearch for obvious reasons. IBMWatson and AI are the words thats are used as hashtags for both the topics. We observe that in Reasearch 'ibm watson' or 'watson' word has been a lot, which says watson is used in research as well.**
**We also noticed that handles like @Ale_Curioni & @banavar holds high position in IBM research department while @davidwkenny & @coastw for IBM Watson department**

